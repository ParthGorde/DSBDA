Steps for running Word count- Map-Reduce example­
1. format hadoop namenode 
	home/hduser: ~$ hadoop namenode -format 
Note that hadoop namenode -format command should be executed once before we start using Hadoop. If this command is executed again after Hadoop has been used, it'll destroy all the data on the Hadoop file system. 
1. 
Create directory on home WordCountAss – place WordCount.java to this directory 

2. 
Create directory on home WordCountAss / input – to place a file ‘input.text’ 

3. 
Create directory on home WordCountAss / Wc_Classes – to place all class files of compiled WordCount.java 


2. start all dfs and yarn deomans home/hduser: ~$ start-all.sh home/hduser: ~$ jps 
[ Make sure that all dfs and yarn deomans are running, if not stop all deomans and then remove and recreate datanode and namenode diecrtories in hadoop space] 
3.
 Set classpath home/hduser: ~$ export HADOOP_CLASSPATH=$(hadoop classpath) home/hduser: ~$ echo $HADOOP_CLASSPATH 

4.
 Create directotries on hadoop file system home/hduser: ~$ hadoop dfs -mkdir /wc home/hduser: ~$ hadoop dfs -mkdir /wc  /wc/input 

5.
 Place input.txt on hadoop file system          home/hduser: ~$ hadoop fs -put '/home/hduser/WordCountAss/input/input.txt' /wc/input 

6.
 Check on namenode web interface if file is copied on hadoop file system 

7.
 Compile WordCount.java home/hduser: ~$ cdWordCountAss home/hduser/WordCountAss: ~$ javac -classpath 


${HADOOP_CLASSPATH}-d'/home/hduser/WordCountAss/WC_classes' '/home/hduser/WC/WordCount.java' 
8.
 Create jar  file home/hduser/WordCountAss: ~$ jar cvf wc2.jar-CWC_classes/. 

9.
 execute jar. 


home/hduser/WordCountAss: ~$ hadoop jar /home/hduser/WordCountAss/wc2.jar WordCount /wc/input /wc/output 
10.
 Successful execution, observe the output at hadoop file system and copy the the same to view 

on terminal. home/hduser/WordCountAss: ~ $ hadoop dfs -cat /wc/output/* 

11.
 stop all deamons home/hduser: ~$ stop-all.sh 



